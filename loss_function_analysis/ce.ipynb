{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Begin test......\n",
      "Test Loss: 0.0157 Acc: 0.2968 Precision: 0.3229 Recall: 0.2968 f1score_micro: 0.2968 f1score_macro: 0.2609\n",
      "Epoch: 2/30\n",
      "Begin test......\n",
      "Test Loss: 0.0133 Acc: 0.3766 Precision: 0.3725 Recall: 0.3766 f1score_micro: 0.3766 f1score_macro: 0.3502\n",
      "Epoch: 3/30\n",
      "Begin test......\n",
      "Test Loss: 0.0134 Acc: 0.3753 Precision: 0.3833 Recall: 0.3753 f1score_micro: 0.3753 f1score_macro: 0.3554\n",
      "Epoch: 4/30\n",
      "Begin test......\n",
      "Test Loss: 0.0127 Acc: 0.4092 Precision: 0.4284 Recall: 0.4092 f1score_micro: 0.4092 f1score_macro: 0.3936\n",
      "Epoch: 5/30\n",
      "Begin test......\n",
      "Test Loss: 0.0127 Acc: 0.4187 Precision: 0.4255 Recall: 0.4187 f1score_micro: 0.4187 f1score_macro: 0.4042\n",
      "Epoch: 6/30\n",
      "Begin test......\n",
      "Test Loss: 0.0113 Acc: 0.4711 Precision: 0.4740 Recall: 0.4711 f1score_micro: 0.4711 f1score_macro: 0.4597\n",
      "Epoch: 7/30\n",
      "Begin test......\n",
      "Test Loss: 0.0114 Acc: 0.4764 Precision: 0.4813 Recall: 0.4764 f1score_micro: 0.4764 f1score_macro: 0.4680\n",
      "Epoch: 8/30\n",
      "Begin test......\n",
      "Test Loss: 0.0113 Acc: 0.4781 Precision: 0.4908 Recall: 0.4781 f1score_micro: 0.4781 f1score_macro: 0.4738\n",
      "Epoch: 9/30\n",
      "Begin test......\n",
      "Test Loss: 0.0111 Acc: 0.4896 Precision: 0.4983 Recall: 0.4896 f1score_micro: 0.4896 f1score_macro: 0.4796\n",
      "Epoch: 10/30\n",
      "Begin test......\n",
      "Test Loss: 0.0110 Acc: 0.5004 Precision: 0.5012 Recall: 0.5004 f1score_micro: 0.5004 f1score_macro: 0.4956\n",
      "Epoch: 11/30\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5157 Precision: 0.5122 Recall: 0.5157 f1score_micro: 0.5157 f1score_macro: 0.5071\n",
      "Epoch: 12/30\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5170 Precision: 0.5175 Recall: 0.5170 f1score_micro: 0.5170 f1score_macro: 0.5056\n",
      "Epoch: 13/30\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5210 Precision: 0.5226 Recall: 0.5210 f1score_micro: 0.5210 f1score_macro: 0.5174\n",
      "Epoch: 14/30\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.5317 Precision: 0.5461 Recall: 0.5317 f1score_micro: 0.5317 f1score_macro: 0.5345\n",
      "Epoch: 15/30\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5241 Precision: 0.5325 Recall: 0.5241 f1score_micro: 0.5241 f1score_macro: 0.5223\n",
      "Epoch: 16/30\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5560 Precision: 0.5571 Recall: 0.5560 f1score_micro: 0.5560 f1score_macro: 0.5483\n",
      "Epoch: 17/30\n",
      "Begin test......\n",
      "Test Loss: 0.0100 Acc: 0.5468 Precision: 0.5541 Recall: 0.5468 f1score_micro: 0.5468 f1score_macro: 0.5422\n",
      "Epoch: 18/30\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5623 Precision: 0.5611 Recall: 0.5623 f1score_micro: 0.5623 f1score_macro: 0.5582\n",
      "Epoch: 19/30\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5491 Precision: 0.5624 Recall: 0.5491 f1score_micro: 0.5491 f1score_macro: 0.5473\n",
      "Epoch: 20/30\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5493 Precision: 0.5554 Recall: 0.5493 f1score_micro: 0.5493 f1score_macro: 0.5420\n",
      "Epoch: 21/30\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5729 Precision: 0.5723 Recall: 0.5729 f1score_micro: 0.5729 f1score_macro: 0.5662\n",
      "Epoch: 22/30\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5786 Precision: 0.5746 Recall: 0.5786 f1score_micro: 0.5786 f1score_macro: 0.5726\n",
      "Epoch: 23/30\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5755 Precision: 0.5733 Recall: 0.5755 f1score_micro: 0.5755 f1score_macro: 0.5702\n",
      "Epoch: 24/30\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5720 Precision: 0.5747 Recall: 0.5720 f1score_micro: 0.5720 f1score_macro: 0.5682\n",
      "Epoch: 25/30\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5679 Precision: 0.5713 Recall: 0.5679 f1score_micro: 0.5679 f1score_macro: 0.5660\n",
      "Epoch: 26/30\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.5848 Precision: 0.5828 Recall: 0.5848 f1score_micro: 0.5848 f1score_macro: 0.5807\n",
      "Epoch: 27/30\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.5864 Precision: 0.5851 Recall: 0.5864 f1score_micro: 0.5864 f1score_macro: 0.5829\n",
      "Epoch: 28/30\n",
      "Begin test......\n",
      "Test Loss: 0.0093 Acc: 0.5826 Precision: 0.5823 Recall: 0.5826 f1score_micro: 0.5826 f1score_macro: 0.5795\n",
      "Epoch: 29/30\n",
      "Begin test......\n",
      "Test Loss: 0.0093 Acc: 0.5777 Precision: 0.5815 Recall: 0.5777 f1score_micro: 0.5777 f1score_macro: 0.5768\n",
      "Epoch: 30/30\n",
      "Begin test......\n",
      "Test Loss: 0.0091 Acc: 0.5878 Precision: 0.5845 Recall: 0.5878 f1score_micro: 0.5878 f1score_macro: 0.5852\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/ce.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
