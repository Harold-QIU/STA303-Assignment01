{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from focal import FocalLoss\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = FocalLoss(gamma=2, reduction='mean')\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.3351 Precision: 0.3762 Recall: 0.3351 f1score_micro: 0.3351 f1score_macro: 0.3224\n",
      "Epoch: 2/30\n",
      "Begin test......\n",
      "Test Loss: 0.0093 Acc: 0.3808 Precision: 0.4261 Recall: 0.3808 f1score_micro: 0.3808 f1score_macro: 0.3621\n",
      "Epoch: 3/30\n",
      "Begin test......\n",
      "Test Loss: 0.0088 Acc: 0.4095 Precision: 0.4265 Recall: 0.4095 f1score_micro: 0.4095 f1score_macro: 0.4128\n",
      "Epoch: 4/30\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.4206 Precision: 0.4168 Recall: 0.4206 f1score_micro: 0.4206 f1score_macro: 0.4048\n",
      "Epoch: 5/30\n",
      "Begin test......\n",
      "Test Loss: 0.0089 Acc: 0.4033 Precision: 0.4190 Recall: 0.4033 f1score_micro: 0.4033 f1score_macro: 0.4046\n",
      "Epoch: 6/30\n",
      "Begin test......\n",
      "Test Loss: 0.0078 Acc: 0.4622 Precision: 0.4616 Recall: 0.4622 f1score_micro: 0.4622 f1score_macro: 0.4521\n",
      "Epoch: 7/30\n",
      "Begin test......\n",
      "Test Loss: 0.0077 Acc: 0.4603 Precision: 0.4686 Recall: 0.4603 f1score_micro: 0.4603 f1score_macro: 0.4465\n",
      "Epoch: 8/30\n",
      "Begin test......\n",
      "Test Loss: 0.0078 Acc: 0.4507 Precision: 0.4609 Recall: 0.4507 f1score_micro: 0.4507 f1score_macro: 0.4479\n",
      "Epoch: 9/30\n",
      "Begin test......\n",
      "Test Loss: 0.0077 Acc: 0.4590 Precision: 0.4769 Recall: 0.4590 f1score_micro: 0.4590 f1score_macro: 0.4350\n",
      "Epoch: 10/30\n",
      "Begin test......\n",
      "Test Loss: 0.0075 Acc: 0.4757 Precision: 0.4921 Recall: 0.4757 f1score_micro: 0.4757 f1score_macro: 0.4638\n",
      "Epoch: 11/30\n",
      "Begin test......\n",
      "Test Loss: 0.0072 Acc: 0.4873 Precision: 0.4963 Recall: 0.4873 f1score_micro: 0.4873 f1score_macro: 0.4763\n",
      "Epoch: 12/30\n",
      "Begin test......\n",
      "Test Loss: 0.0070 Acc: 0.5058 Precision: 0.5165 Recall: 0.5058 f1score_micro: 0.5058 f1score_macro: 0.5023\n",
      "Epoch: 13/30\n",
      "Begin test......\n",
      "Test Loss: 0.0070 Acc: 0.5057 Precision: 0.5088 Recall: 0.5057 f1score_micro: 0.5057 f1score_macro: 0.4944\n",
      "Epoch: 14/30\n",
      "Begin test......\n",
      "Test Loss: 0.0068 Acc: 0.5174 Precision: 0.5190 Recall: 0.5174 f1score_micro: 0.5174 f1score_macro: 0.5161\n",
      "Epoch: 15/30\n",
      "Begin test......\n",
      "Test Loss: 0.0069 Acc: 0.5112 Precision: 0.5212 Recall: 0.5112 f1score_micro: 0.5112 f1score_macro: 0.5027\n",
      "Epoch: 16/30\n",
      "Begin test......\n",
      "Test Loss: 0.0066 Acc: 0.5340 Precision: 0.5371 Recall: 0.5340 f1score_micro: 0.5340 f1score_macro: 0.5309\n",
      "Epoch: 17/30\n",
      "Begin test......\n",
      "Test Loss: 0.0066 Acc: 0.5234 Precision: 0.5274 Recall: 0.5234 f1score_micro: 0.5234 f1score_macro: 0.5209\n",
      "Epoch: 18/30\n",
      "Begin test......\n",
      "Test Loss: 0.0066 Acc: 0.5242 Precision: 0.5281 Recall: 0.5242 f1score_micro: 0.5242 f1score_macro: 0.5194\n",
      "Epoch: 19/30\n",
      "Begin test......\n",
      "Test Loss: 0.0065 Acc: 0.5353 Precision: 0.5364 Recall: 0.5353 f1score_micro: 0.5353 f1score_macro: 0.5306\n",
      "Epoch: 20/30\n",
      "Begin test......\n",
      "Test Loss: 0.0065 Acc: 0.5270 Precision: 0.5396 Recall: 0.5270 f1score_micro: 0.5270 f1score_macro: 0.5239\n",
      "Epoch: 21/30\n",
      "Begin test......\n",
      "Test Loss: 0.0064 Acc: 0.5381 Precision: 0.5426 Recall: 0.5381 f1score_micro: 0.5381 f1score_macro: 0.5367\n",
      "Epoch: 22/30\n",
      "Begin test......\n",
      "Test Loss: 0.0064 Acc: 0.5390 Precision: 0.5492 Recall: 0.5390 f1score_micro: 0.5390 f1score_macro: 0.5382\n",
      "Epoch: 23/30\n",
      "Begin test......\n",
      "Test Loss: 0.0064 Acc: 0.5434 Precision: 0.5401 Recall: 0.5434 f1score_micro: 0.5434 f1score_macro: 0.5382\n",
      "Epoch: 24/30\n",
      "Begin test......\n",
      "Test Loss: 0.0063 Acc: 0.5408 Precision: 0.5400 Recall: 0.5408 f1score_micro: 0.5408 f1score_macro: 0.5365\n",
      "Epoch: 25/30\n",
      "Begin test......\n",
      "Test Loss: 0.0063 Acc: 0.5396 Precision: 0.5425 Recall: 0.5396 f1score_micro: 0.5396 f1score_macro: 0.5367\n",
      "Epoch: 26/30\n",
      "Begin test......\n",
      "Test Loss: 0.0062 Acc: 0.5477 Precision: 0.5487 Recall: 0.5477 f1score_micro: 0.5477 f1score_macro: 0.5469\n",
      "Epoch: 27/30\n",
      "Begin test......\n",
      "Test Loss: 0.0061 Acc: 0.5479 Precision: 0.5455 Recall: 0.5479 f1score_micro: 0.5479 f1score_macro: 0.5458\n",
      "Epoch: 28/30\n",
      "Begin test......\n",
      "Test Loss: 0.0062 Acc: 0.5487 Precision: 0.5465 Recall: 0.5487 f1score_micro: 0.5487 f1score_macro: 0.5467\n",
      "Epoch: 29/30\n",
      "Begin test......\n",
      "Test Loss: 0.0062 Acc: 0.5535 Precision: 0.5487 Recall: 0.5535 f1score_micro: 0.5535 f1score_macro: 0.5491\n",
      "Epoch: 30/30\n",
      "Begin test......\n",
      "Test Loss: 0.0062 Acc: 0.5517 Precision: 0.5519 Recall: 0.5517 f1score_micro: 0.5517 f1score_macro: 0.5496\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/focal_2.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
