{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = nn.L1Loss()\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(F.softmax(output, dim=1), F.one_hot(target, num_classes=10))\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(F.softmax(output, dim=1), F.one_hot(target, num_classes=10))\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Begin test......\n",
      "Test Loss: 0.0013 Acc: 0.1601 Precision: 0.0797 Recall: 0.1601 f1score_micro: 0.1601 f1score_macro: 0.0598\n",
      "Epoch: 2/30\n",
      "Begin test......\n",
      "Test Loss: 0.0012 Acc: 0.2593 Precision: 0.1573 Recall: 0.2593 f1score_micro: 0.2593 f1score_macro: 0.1783\n",
      "Epoch: 3/30\n",
      "Begin test......\n",
      "Test Loss: 0.0012 Acc: 0.2672 Precision: 0.1471 Recall: 0.2672 f1score_micro: 0.2672 f1score_macro: 0.1850\n",
      "Epoch: 4/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.2756 Precision: 0.1609 Recall: 0.2756 f1score_micro: 0.2756 f1score_macro: 0.1948\n",
      "Epoch: 5/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.2933 Precision: 0.1618 Recall: 0.2933 f1score_micro: 0.2933 f1score_macro: 0.2001\n",
      "Epoch: 6/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.2987 Precision: 0.1539 Recall: 0.2987 f1score_micro: 0.2987 f1score_macro: 0.2003\n",
      "Epoch: 7/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3023 Precision: 0.1700 Recall: 0.3023 f1score_micro: 0.3023 f1score_macro: 0.2083\n",
      "Epoch: 8/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3111 Precision: 0.1696 Recall: 0.3111 f1score_micro: 0.3111 f1score_macro: 0.2131\n",
      "Epoch: 9/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3023 Precision: 0.1655 Recall: 0.3023 f1score_micro: 0.3023 f1score_macro: 0.2071\n",
      "Epoch: 10/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3207 Precision: 0.1761 Recall: 0.3207 f1score_micro: 0.3207 f1score_macro: 0.2204\n",
      "Epoch: 11/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3263 Precision: 0.1884 Recall: 0.3263 f1score_micro: 0.3263 f1score_macro: 0.2277\n",
      "Epoch: 12/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3245 Precision: 0.1707 Recall: 0.3245 f1score_micro: 0.3245 f1score_macro: 0.2197\n",
      "Epoch: 13/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3328 Precision: 0.1838 Recall: 0.3328 f1score_micro: 0.3328 f1score_macro: 0.2288\n",
      "Epoch: 14/30\n",
      "Begin test......\n",
      "Test Loss: 0.0011 Acc: 0.3301 Precision: 0.1894 Recall: 0.3301 f1score_micro: 0.3301 f1score_macro: 0.2291\n",
      "Epoch: 15/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3392 Precision: 0.1800 Recall: 0.3392 f1score_micro: 0.3392 f1score_macro: 0.2302\n",
      "Epoch: 16/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3450 Precision: 0.1846 Recall: 0.3450 f1score_micro: 0.3450 f1score_macro: 0.2351\n",
      "Epoch: 17/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3427 Precision: 0.1885 Recall: 0.3427 f1score_micro: 0.3427 f1score_macro: 0.2351\n",
      "Epoch: 18/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3492 Precision: 0.1862 Recall: 0.3492 f1score_micro: 0.3492 f1score_macro: 0.2374\n",
      "Epoch: 19/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3513 Precision: 0.1936 Recall: 0.3513 f1score_micro: 0.3513 f1score_macro: 0.2413\n",
      "Epoch: 20/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3481 Precision: 0.1902 Recall: 0.3481 f1score_micro: 0.3481 f1score_macro: 0.2383\n",
      "Epoch: 21/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3520 Precision: 0.1912 Recall: 0.3520 f1score_micro: 0.3520 f1score_macro: 0.2407\n",
      "Epoch: 22/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3527 Precision: 0.1938 Recall: 0.3527 f1score_micro: 0.3527 f1score_macro: 0.2424\n",
      "Epoch: 23/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3529 Precision: 0.1943 Recall: 0.3529 f1score_micro: 0.3529 f1score_macro: 0.2423\n",
      "Epoch: 24/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3533 Precision: 0.1855 Recall: 0.3533 f1score_micro: 0.3533 f1score_macro: 0.2394\n",
      "Epoch: 25/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3564 Precision: 0.1963 Recall: 0.3564 f1score_micro: 0.3564 f1score_macro: 0.2450\n",
      "Epoch: 26/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3560 Precision: 0.1925 Recall: 0.3560 f1score_micro: 0.3560 f1score_macro: 0.2438\n",
      "Epoch: 27/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3569 Precision: 0.1934 Recall: 0.3569 f1score_micro: 0.3569 f1score_macro: 0.2440\n",
      "Epoch: 28/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3563 Precision: 0.1905 Recall: 0.3563 f1score_micro: 0.3563 f1score_macro: 0.2428\n",
      "Epoch: 29/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3569 Precision: 0.1959 Recall: 0.3569 f1score_micro: 0.3569 f1score_macro: 0.2452\n",
      "Epoch: 30/30\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.3553 Precision: 0.1896 Recall: 0.3553 f1score_micro: 0.3553 f1score_macro: 0.2420\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/mae.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
