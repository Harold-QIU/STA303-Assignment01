{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports | Hyperparameters | Device | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from focal import FocalLoss\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "## Hyperparameters \n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "## Device\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Dataset\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model def\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "## Init model\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "## Init Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Modify here ###########################\n",
    "# Define the loss function\n",
    "criterion = FocalLoss(gamma=0.5, reduction='mean')\n",
    "###############################################################\n",
    "\n",
    "## Define the batch train\n",
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### Modify here ###########################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### Modify here ###########################\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.3763 Precision: 0.3964 Recall: 0.3763 f1score_micro: 0.3763 f1score_macro: 0.3617\n",
      "Epoch: 2/30\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.3791 Precision: 0.3794 Recall: 0.3791 f1score_micro: 0.3791 f1score_macro: 0.3649\n",
      "Epoch: 3/30\n",
      "Begin test......\n",
      "Test Loss: 0.0113 Acc: 0.4188 Precision: 0.4430 Recall: 0.4188 f1score_micro: 0.4188 f1score_macro: 0.4218\n",
      "Epoch: 4/30\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.3865 Precision: 0.3967 Recall: 0.3865 f1score_micro: 0.3865 f1score_macro: 0.3613\n",
      "Epoch: 5/30\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.3926 Precision: 0.4008 Recall: 0.3926 f1score_micro: 0.3926 f1score_macro: 0.3793\n",
      "Epoch: 6/30\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.4581 Precision: 0.4770 Recall: 0.4581 f1score_micro: 0.4581 f1score_macro: 0.4484\n",
      "Epoch: 7/30\n",
      "Begin test......\n",
      "Test Loss: 0.0100 Acc: 0.4768 Precision: 0.4787 Recall: 0.4768 f1score_micro: 0.4768 f1score_macro: 0.4657\n",
      "Epoch: 8/30\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.4604 Precision: 0.4712 Recall: 0.4604 f1score_micro: 0.4604 f1score_macro: 0.4542\n",
      "Epoch: 9/30\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.4499 Precision: 0.4679 Recall: 0.4499 f1score_micro: 0.4499 f1score_macro: 0.4367\n",
      "Epoch: 10/30\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.4669 Precision: 0.4908 Recall: 0.4669 f1score_micro: 0.4669 f1score_macro: 0.4593\n",
      "Epoch: 11/30\n",
      "Begin test......\n",
      "Test Loss: 0.0094 Acc: 0.5167 Precision: 0.5122 Recall: 0.5167 f1score_micro: 0.5167 f1score_macro: 0.5084\n",
      "Epoch: 12/30\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.5267 Precision: 0.5242 Recall: 0.5267 f1score_micro: 0.5267 f1score_macro: 0.5171\n",
      "Epoch: 13/30\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.5281 Precision: 0.5259 Recall: 0.5281 f1score_micro: 0.5281 f1score_macro: 0.5197\n",
      "Epoch: 14/30\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.5281 Precision: 0.5258 Recall: 0.5281 f1score_micro: 0.5281 f1score_macro: 0.5238\n",
      "Epoch: 15/30\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.5294 Precision: 0.5262 Recall: 0.5294 f1score_micro: 0.5294 f1score_macro: 0.5230\n",
      "Epoch: 16/30\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.5515 Precision: 0.5458 Recall: 0.5515 f1score_micro: 0.5515 f1score_macro: 0.5463\n",
      "Epoch: 17/30\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.5526 Precision: 0.5523 Recall: 0.5526 f1score_micro: 0.5526 f1score_macro: 0.5496\n",
      "Epoch: 18/30\n",
      "Begin test......\n",
      "Test Loss: 0.0088 Acc: 0.5475 Precision: 0.5538 Recall: 0.5475 f1score_micro: 0.5475 f1score_macro: 0.5394\n",
      "Epoch: 19/30\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.5586 Precision: 0.5596 Recall: 0.5586 f1score_micro: 0.5586 f1score_macro: 0.5573\n",
      "Epoch: 20/30\n",
      "Begin test......\n",
      "Test Loss: 0.0087 Acc: 0.5522 Precision: 0.5496 Recall: 0.5522 f1score_micro: 0.5522 f1score_macro: 0.5454\n",
      "Epoch: 21/30\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5643 Precision: 0.5623 Recall: 0.5643 f1score_micro: 0.5643 f1score_macro: 0.5594\n",
      "Epoch: 22/30\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5615 Precision: 0.5592 Recall: 0.5615 f1score_micro: 0.5615 f1score_macro: 0.5563\n",
      "Epoch: 23/30\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5644 Precision: 0.5629 Recall: 0.5644 f1score_micro: 0.5644 f1score_macro: 0.5595\n",
      "Epoch: 24/30\n",
      "Begin test......\n",
      "Test Loss: 0.0084 Acc: 0.5702 Precision: 0.5699 Recall: 0.5702 f1score_micro: 0.5702 f1score_macro: 0.5678\n",
      "Epoch: 25/30\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.5587 Precision: 0.5610 Recall: 0.5587 f1score_micro: 0.5587 f1score_macro: 0.5549\n",
      "Epoch: 26/30\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.5754 Precision: 0.5694 Recall: 0.5754 f1score_micro: 0.5754 f1score_macro: 0.5705\n",
      "Epoch: 27/30\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.5717 Precision: 0.5668 Recall: 0.5717 f1score_micro: 0.5717 f1score_macro: 0.5663\n",
      "Epoch: 28/30\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.5768 Precision: 0.5731 Recall: 0.5768 f1score_micro: 0.5768 f1score_macro: 0.5732\n",
      "Epoch: 29/30\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.5806 Precision: 0.5772 Recall: 0.5806 f1score_micro: 0.5806 f1score_macro: 0.5774\n",
      "Epoch: 30/30\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.5768 Precision: 0.5748 Recall: 0.5768 f1score_micro: 0.5768 f1score_macro: 0.5729\n"
     ]
    }
   ],
   "source": [
    "test_loss_l = []\n",
    "test_acc_l = []\n",
    "test_precision_l = []\n",
    "test_recall_l = []\n",
    "test_f1score_micro_l = []\n",
    "test_f1score_macro_l = []\n",
    "\n",
    "test_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=10).to(device)\n",
    "test_precision = torchmetrics.classification.MulticlassPrecision(num_classes=10, average='macro').to(device)\n",
    "test_recall = torchmetrics.classification.MulticlassRecall(num_classes=10, average='macro').to(device)\n",
    "test_f1score_micro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='micro').to(device)\n",
    "test_f1score_macro = torchmetrics.classification.MulticlassF1Score(num_classes=10, average='macro').to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = .0        \n",
    "        test_acc.reset()\n",
    "        test_precision.reset()    \n",
    "        test_recall.reset()\n",
    "        test_f1score_micro.reset()\n",
    "        test_f1score_macro.reset()\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc.update(preds, target)\n",
    "            test_precision.update(preds, target)\n",
    "            test_recall.update(preds, target)\n",
    "            test_f1score_micro.update(preds, target)\n",
    "            test_f1score_macro.update(preds, target)\n",
    "\n",
    "        val_loss = test_loss / len(test_set)\n",
    "        val_acc = test_acc.compute()\n",
    "        val_precision = test_precision.compute()\n",
    "        val_recall = test_recall.compute()\n",
    "        val_f1score_micro = test_f1score_micro.compute()\n",
    "        val_f1score_macro = test_f1score_macro.compute()\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f} f1score_micro: {val_f1score_micro:.4f} f1score_macro: {val_f1score_macro:.4f}')\n",
    "\n",
    "        test_loss_l.append(test_loss)\n",
    "        test_acc_l.append(val_acc.cpu().detach().numpy())\n",
    "        test_precision_l.append(val_precision.cpu().detach().numpy())\n",
    "        test_recall_l.append(val_recall.cpu().detach().numpy())\n",
    "        test_f1score_micro_l.append(val_f1score_micro.cpu().numpy())\n",
    "        test_f1score_macro_l.append(val_f1score_macro.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log generated\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'acc': test_acc_l, 'precision': test_precision_l, 'recall': test_recall_l, 'f1score_micro': test_f1score_micro_l, 'f1score_macro': test_f1score_macro_l})\n",
    "df.to_csv('./log/focal_0.5.csv', index=False)\n",
    "print('log generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
